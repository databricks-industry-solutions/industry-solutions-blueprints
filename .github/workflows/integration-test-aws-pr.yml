name: AWS integration test PR

on:
 pull_request:

jobs:
 run-databricks-notebook:
   runs-on: ubuntu-latest
   steps:
     - name: Checkout repo
       uses: actions/checkout@v2
     - name: Run a databricks notebook
       uses: databricks/run-notebook@v0
       with:
         local-notebook-path: RUNME.py
         git-commit: $GITHUB_SHA
         databricks-host: ${{ secrets.DEPLOYMENT_TARGET_URL_AWS }}
         databricks-token: ${{ secrets.DEPLOYMENT_TARGET_TOKEN_AWS }}
         new-cluster-json: >
           {
             "num_workers": 1,
             "spark_version": "10.4.x-scala2.12",
             "node_type_id": "i3.xlarge",
             "aws_attributes": {"first_on_demand": 1,"availability": "ON_DEMAND"}
           }
         notebook-params-json: >
           {
            "run_job": "True"
           }
           
